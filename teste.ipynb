{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from conllu import parse_incr\n",
    "\n",
    "# Dictionnaire de mapping XPOS vers C8\n",
    "xpos_to_c8 = {\n",
    "    \"WDT\": \"WPR\",  # Relative pronoun, \"that\"\n",
    "    \"IN\": \"CST\",   # Conjunction for nouns, \"the fact that\"\n",
    "    \"CJT\": \"CJT\",  # Conjunction for verbs, \"I think that\"\n",
    "    \"DT\": \"DT\",    # Singular determiner, \"that\"\n",
    "    \"RB\": \"RB\"     # Adverb, \"it's not that difficult\"\n",
    "}\n",
    "\n",
    "def prepare_training_data_with_mapping(conllu_file, output_file, tag_mapping):\n",
    "    \"\"\"\n",
    "    Prépare un corpus d'entraînement TreeTagger à partir d'un fichier CoNLL-U,\n",
    "    en appliquant un mapping des tags XPOS vers un tagset C8 pour tous les mots.\n",
    "    Compte également les occurrences de 'that' pour chaque catégorie.\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    that_count = 0\n",
    "    category_counts = defaultdict(int)\n",
    "    \n",
    "    with open(conllu_file, 'r', encoding='utf-8') as infile:\n",
    "        for tokenlist in parse_incr(infile):  # Analyse incrémentale du fichier\n",
    "            for token in tokenlist:\n",
    "                word = token.get(\"form\")\n",
    "                lemma = token.get(\"lemma\")\n",
    "                xpos = token.get(\"xpos\")\n",
    "                \n",
    "                # Appliquer le mapping des tags XPOS vers C8 si applicable\n",
    "                c8_tag = tag_mapping.get(xpos, xpos)  # Utiliser le tag original si non mappé\n",
    "                \n",
    "                # Compter les occurrences de 'that' pour chaque catégorie\n",
    "                if word.lower() == \"that\":\n",
    "                    category_counts[c8_tag] += 1\n",
    "                    that_count += 1\n",
    "                \n",
    "                # Ajouter la ligne formatée au corpus\n",
    "                if word and lemma and xpos:\n",
    "                    training_data.append(f\"{word}\\t{c8_tag}\\t{lemma}\")\n",
    "            \n",
    "            # Ajouter une ligne vide pour séparer les phrases\n",
    "            training_data.append(\"\")\n",
    "    \n",
    "    # Sauvegarder le corpus préparé\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(\"\\n\".join(training_data))\n",
    "    \n",
    "    print(f\"Corpus d'entraînement sauvegardé dans : {output_file}\")\n",
    "    \n",
    "    # Afficher le nombre total d'occurrences de 'that'\n",
    "    print(f\"Nombre total d'occurrences de 'that': {that_count}\")\n",
    "    \n",
    "    # Afficher le nombre d'occurrences de 'that' pour chaque catégorie\n",
    "    print(\"Nombre d'occurrences de 'that' pour chaque catégorie :\")\n",
    "    for category, count in category_counts.items():\n",
    "        print(f\"{category}: {count}\")\n",
    "\n",
    "# Fichiers d'entrée et de sortie\n",
    "conllu_file = \"training_data/en_partut-ud-train.conllu\"  # Remplacez par le chemin de votre fichier d'entraînement\n",
    "output_file = \"corpus_mapped_that_c8_partut_xpos.txt\"  # Chemin du fichier de sortie\n",
    "\n",
    "# Préparer les données avec mapping global\n",
    "prepare_training_data_with_mapping(conllu_file, output_file, xpos_to_c8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
